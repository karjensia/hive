From 4144cd94a155d1cda828e52f6f881a430cc7aaf4 Mon Sep 17 00:00:00 2001
From: dengzh <dengzhhu653@gmail.com>
Date: Wed, 23 Nov 2022 18:16:57 +0800
Subject: [PATCH 5028/5664] =?UTF-8?q?HIVE-26701:=20Enable=20metrics=20for?=
 =?UTF-8?q?=20connection=20pools=20used=20by=20ObjectStore=20i=E2=80=A6=20?=
 =?UTF-8?q?(#3773)?=
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 8bit

* HIVE-26701: Enable metrics for connection pools used by ObjectStore in HMS

* close underlying pools when PersistenceManagerFactory changes

* add unit test

* txn -> txnhandler
---
 .../hive/metastore/TestMetaStoreMetrics.java       | 14 +++++++
 .../apache/hadoop/hive/metastore/HMSHandler.java   | 26 ++++---------
 .../hive/metastore/PersistenceManagerProvider.java | 39 ++++++++++++++++---
 .../metastore/datasource/DataSourceProvider.java   | 20 ++++++++++
 .../datasource/DbCPDataSourceProvider.java         |  4 +-
 .../datasource/HikariCPDataSourceProvider.java     |  8 +++-
 .../hadoop/hive/metastore/metrics/Metrics.java     |  3 +-
 .../hive/metastore/txn/CompactionTxnHandler.java   |  6 ++-
 .../hadoop/hive/metastore/txn/TxnHandler.java      | 14 ++++---
 .../datasource/TestDataSourceProviderFactory.java  | 44 ++++++++++++++++++++++
 10 files changed, 143 insertions(+), 35 deletions(-)

diff --git a/itests/hive-unit/src/test/java/org/apache/hadoop/hive/metastore/TestMetaStoreMetrics.java b/itests/hive-unit/src/test/java/org/apache/hadoop/hive/metastore/TestMetaStoreMetrics.java
index 694bad5..2f7a260 100644
--- a/itests/hive-unit/src/test/java/org/apache/hadoop/hive/metastore/TestMetaStoreMetrics.java
+++ b/itests/hive-unit/src/test/java/org/apache/hadoop/hive/metastore/TestMetaStoreMetrics.java
@@ -19,6 +19,7 @@
 
 import org.apache.hadoop.hive.cli.CliSessionState;
 import org.apache.hadoop.hive.conf.HiveConf;
+import org.apache.hadoop.hive.metastore.conf.MetastoreConf;
 import org.apache.hadoop.hive.metastore.metrics.Metrics;
 import org.apache.hadoop.hive.metastore.metrics.MetricsConstants;
 import org.apache.hadoop.hive.ql.DriverFactory;
@@ -156,4 +157,17 @@ public void testConnections() throws Exception {
     Assert.assertEquals(initialCount,
         Metrics.getRegistry().getCounters().get(MetricsConstants.OPEN_CONNECTIONS).getCount());
   }
+
+  @Test
+  public void testConnectionPoolMetrics() {
+    // The connection pool's metric is in a pattern of ${poolName}.pool.${metricName}
+    String secondaryPoolMetricName = "objectstore-secondary.pool.TotalConnections";
+    String poolMetricName = "objectstore.pool.TotalConnections";
+    Assert.assertEquals(MetastoreConf.getIntVar(hiveConf,
+        MetastoreConf.ConfVars.CONNECTION_POOLING_MAX_CONNECTIONS),
+        Metrics.getRegistry().getGauges().get(poolMetricName).getValue());
+    Assert.assertEquals(2,
+        Metrics.getRegistry().getGauges().get(secondaryPoolMetricName).getValue());
+  }
+
 }
diff --git a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/HMSHandler.java b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/HMSHandler.java
index 97b3925..9b88220 100644
--- a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/HMSHandler.java
+++ b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/HMSHandler.java
@@ -152,10 +152,6 @@
   private IMetaStoreMetadataTransformer transformer;
   private static DataConnectorProviderFactory dataconnectorFactory = null;
 
-  // Variables for metrics
-  // Package visible so that HMSMetricsListener can see them.
-  static AtomicInteger databaseCount, tableCount, partCount;
-
   public static final String PARTITION_NUMBER_EXCEED_LIMIT_MSG =
       "Number of partitions scanned (=%d) on table '%s' exceeds limit (=%d). This is controlled on the metastore server by %s.";
 
@@ -341,6 +337,7 @@ public Configuration getHiveConf() {
 
   @Override
   public void init() throws MetaException {
+    Metrics.initialize(conf);
     initListeners = MetaStoreServerUtils.getMetaStoreListeners(
         MetaStoreInitListener.class, conf, MetastoreConf.getVar(conf, ConfVars.INIT_HOOKS));
     for (MetaStoreInitListener singleInitListener: initListeners) {
@@ -359,20 +356,10 @@ public void init() throws MetaException {
         createDefaultRoles();
         addAdminUsers();
         currentUrl = MetaStoreInit.getConnectionURL(conf);
+        updateMetrics();
       }
     }
 
-    //Start Metrics
-    if (MetastoreConf.getBoolVar(conf, ConfVars.METRICS_ENABLED)) {
-      LOG.info("Begin calculating metadata count metrics.");
-      Metrics.initialize(conf);
-      databaseCount = Metrics.getOrCreateGauge(MetricsConstants.TOTAL_DATABASES);
-      tableCount = Metrics.getOrCreateGauge(MetricsConstants.TOTAL_TABLES);
-      partCount = Metrics.getOrCreateGauge(MetricsConstants.TOTAL_PARTITIONS);
-      updateMetrics();
-
-    }
-
     preListeners = MetaStoreServerUtils.getMetaStoreListeners(MetaStorePreEventListener.class,
         conf, MetastoreConf.getVar(conf, ConfVars.PRE_EVENT_LISTENERS));
     preListeners.add(0, new TransactionalValidationListener(conf));
@@ -9658,10 +9645,11 @@ public CacheFileMetadataResult cache_file_metadata(
 
   @VisibleForTesting
   void updateMetrics() throws MetaException {
-    if (databaseCount != null) {
-      tableCount.set(getMS().getTableCount());
-      partCount.set(getMS().getPartitionCount());
-      databaseCount.set(getMS().getDatabaseCount());
+    if (Metrics.getRegistry() != null) {
+      LOG.info("Begin calculating metadata count metrics.");
+      Metrics.getOrCreateGauge(MetricsConstants.TOTAL_DATABASES).set(getMS().getTableCount());
+      Metrics.getOrCreateGauge(MetricsConstants.TOTAL_TABLES).set(getMS().getPartitionCount());
+      Metrics.getOrCreateGauge(MetricsConstants.TOTAL_PARTITIONS).set(getMS().getDatabaseCount());
     }
   }
 
diff --git a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/PersistenceManagerProvider.java b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/PersistenceManagerProvider.java
index cccb1f7..8fa4e6f 100644
--- a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/PersistenceManagerProvider.java
+++ b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/PersistenceManagerProvider.java
@@ -136,6 +136,35 @@ private static boolean isRetriableException(Throwable e) {
     }
     return isRetriableException(e.getCause());
   }
+
+  /**
+   * When closing PersistenceManagerFactory, the connection factory should be closed as well,
+   * otherwise the underlying dangling connections would be accumulated resulting to connection leaks.
+   * See TestDataSourceProviderFactory#testClosePersistenceManagerProvider for details.
+   * @param pmf the PersistenceManagerFactory tended to be closed
+   */
+  @VisibleForTesting
+  public static void closePmfInternal(PersistenceManagerFactory pmf) {
+    if (pmf != null) {
+      LOG.debug("Closing PersistenceManagerFactory");
+      pmf.close();
+      // close the underlying connection pool to avoid leaks
+      if (pmf.getConnectionFactory() instanceof AutoCloseable) {
+        try (AutoCloseable closeable = (AutoCloseable) pmf.getConnectionFactory()) {
+        } catch (Exception e) {
+          LOG.warn("Failed to close connection factory of PersistenceManagerFactory: " + pmf, e);
+        }
+      }
+      if (pmf.getConnectionFactory2() instanceof AutoCloseable) {
+        try (AutoCloseable closeable = (AutoCloseable) pmf.getConnectionFactory2()) {
+        } catch (Exception e) {
+          LOG.warn("Failed to close connection factory2 of PersistenceManagerFactory: " + pmf, e);
+        }
+      }
+      LOG.debug("PersistenceManagerFactory closed");
+    }
+  }
+
   /**
    * This method updates the PersistenceManagerFactory and its properties if the given
    * configuration is different from its current set of properties. Most common case is that
@@ -199,10 +228,7 @@ public static void updatePmfProperties(Configuration conf) {
             if (pmf != null) {
               clearOutPmfClassLoaderCache(pmf);
               if (!forTwoMetastoreTesting) {
-                // close the underlying connection pool to avoid leaks
-                LOG.debug("Closing PersistenceManagerFactory");
-                pmf.close();
-                LOG.debug("PersistenceManagerFactory closed");
+                closePmfInternal(pmf);
               }
               pmf = null;
             }
@@ -251,11 +277,14 @@ private static PersistenceManagerFactory initPMF(Configuration conf, boolean for
     if (dsp == null) {
       pmf = JDOHelper.getPersistenceManagerFactory(dsProp);
     } else {
-      try {
+      String sourceName = forCompactor ? "objectstore-compactor" : "objectstore";
+      try (DataSourceProvider.DataSourceNameConfigurator configurator =
+               new DataSourceProvider.DataSourceNameConfigurator(conf, sourceName)) {
         DataSource ds = (maxPoolSize > 0) ? dsp.create(conf, maxPoolSize) : dsp.create(conf);
         // The secondary connection factory is used for schema generation, and for value generation operations.
         // We should use a different pool for the secondary connection factory to avoid resource starvation.
         // Since DataNucleus uses locks for schema generation and value generation, 2 connections should be sufficient.
+        configurator.resetName("objectstore-secondary");
         DataSource ds2 = forCompactor ? ds : dsp.create(conf, /* maxPoolSize */ 2);
         dsProp.put(PropertyNames.PROPERTY_CONNECTION_FACTORY, ds);
         dsProp.put(PropertyNames.PROPERTY_CONNECTION_FACTORY2, ds2);
diff --git a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/datasource/DataSourceProvider.java b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/datasource/DataSourceProvider.java
index 4e5803e..78fa406 100644
--- a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/datasource/DataSourceProvider.java
+++ b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/datasource/DataSourceProvider.java
@@ -17,6 +17,7 @@
  */
 package org.apache.hadoop.hive.metastore.datasource;
 
+import java.io.Closeable;
 import java.io.IOException;
 import java.sql.SQLException;
 import java.util.Properties;
@@ -79,4 +80,23 @@ static String getMetastoreJdbcDriverUrl(Configuration conf) throws SQLException
     return MetastoreConf.getVar(conf, MetastoreConf.ConfVars.CONNECT_URL_KEY);
   }
 
+  static String getDataSourceName(Configuration conf) {
+    return conf.get(DataSourceNameConfigurator.DATA_SOURCE_NAME);
+  }
+
+  class DataSourceNameConfigurator implements Closeable {
+    static final String DATA_SOURCE_NAME = "metastore.DataSourceProvider.pool.name";
+    private final Configuration configuration;
+    public DataSourceNameConfigurator(Configuration conf, String name) {
+      this.configuration = conf;
+      configuration.set(DATA_SOURCE_NAME, name);
+    }
+    public void resetName(String name) {
+      configuration.set(DATA_SOURCE_NAME, name);
+    }
+    @Override
+    public void close() {
+      configuration.unset(DATA_SOURCE_NAME);
+    }
+  }
 }
diff --git a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/datasource/DbCPDataSourceProvider.java b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/datasource/DbCPDataSourceProvider.java
index 476a3d8..da8d875 100644
--- a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/datasource/DbCPDataSourceProvider.java
+++ b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/datasource/DbCPDataSourceProvider.java
@@ -31,7 +31,6 @@
 import org.apache.commons.pool2.impl.GenericObjectPool;
 import org.apache.hadoop.conf.Configuration;
 import org.apache.hadoop.hive.metastore.DatabaseProduct;
-import org.apache.hadoop.hive.metastore.conf.MetastoreConf;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
@@ -58,7 +57,8 @@
   @SuppressWarnings({ "rawtypes", "unchecked" })
   @Override
   public DataSource create(Configuration hdpConfig, int maxPoolSize) throws SQLException {
-    LOG.debug("Creating dbcp connection pool for the MetaStore");
+    String poolName = DataSourceProvider.getDataSourceName(hdpConfig);
+    LOG.info("Creating dbcp connection pool for the MetaStore, maxPoolSize: {}, name: {}", maxPoolSize, poolName);
 
     String driverUrl = DataSourceProvider.getMetastoreJdbcDriverUrl(hdpConfig);
     String user = DataSourceProvider.getMetastoreJdbcUser(hdpConfig);
diff --git a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/datasource/HikariCPDataSourceProvider.java b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/datasource/HikariCPDataSourceProvider.java
index a48ce47..2c41191 100644
--- a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/datasource/HikariCPDataSourceProvider.java
+++ b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/datasource/HikariCPDataSourceProvider.java
@@ -22,8 +22,8 @@
 import com.zaxxer.hikari.HikariDataSource;
 import org.apache.hadoop.conf.Configuration;
 import org.apache.hadoop.hive.metastore.DatabaseProduct;
-import org.apache.hadoop.hive.metastore.conf.MetastoreConf;
 import org.apache.hadoop.hive.metastore.metrics.Metrics;
+import org.apache.hadoop.hive.metastore.utils.StringUtils;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
@@ -45,7 +45,8 @@
 
   @Override
   public DataSource create(Configuration hdpConfig, int maxPoolSize) throws SQLException {
-    LOG.debug("Creating Hikari connection pool for the MetaStore");
+    String poolName = DataSourceProvider.getDataSourceName(hdpConfig);
+    LOG.info("Creating Hikari connection pool for the MetaStore, maxPoolSize: {}, name: {}", maxPoolSize, poolName);
 
     String driverUrl = DataSourceProvider.getMetastoreJdbcDriverUrl(hdpConfig);
     String user = DataSourceProvider.getMetastoreJdbcUser(hdpConfig);
@@ -67,6 +68,9 @@ public DataSource create(Configuration hdpConfig, int maxPoolSize) throws SQLExc
     config.setUsername(user);
     config.setPassword(passwd);
     config.setLeakDetectionThreshold(leakDetectionThreshold);
+    if (!StringUtils.isEmpty(poolName)) {
+      config.setPoolName(poolName);
+    }
 
     //https://github.com/brettwooldridge/HikariCP
     config.setConnectionTimeout(connectionTimeout);
diff --git a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/metrics/Metrics.java b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/metrics/Metrics.java
index 4b580c8..61732ed 100644
--- a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/metrics/Metrics.java
+++ b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/metrics/Metrics.java
@@ -67,7 +67,8 @@
   private boolean hadoopMetricsStarted;
 
   public static synchronized Metrics initialize(Configuration conf) {
-    if (self == null) {
+    if (self == null && MetastoreConf.getBoolVar(conf,
+        MetastoreConf.ConfVars.METRICS_ENABLED)) {
       self = new Metrics(conf);
     }
     return self;
diff --git a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/txn/CompactionTxnHandler.java b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/txn/CompactionTxnHandler.java
index 027170a..c73a268 100644
--- a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/txn/CompactionTxnHandler.java
+++ b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/txn/CompactionTxnHandler.java
@@ -28,6 +28,7 @@
 import org.apache.hadoop.hive.metastore.api.TxnType;
 import org.apache.hadoop.hive.metastore.conf.MetastoreConf;
 import org.apache.hadoop.hive.metastore.conf.MetastoreConf.ConfVars;
+import org.apache.hadoop.hive.metastore.datasource.DataSourceProvider;
 import org.apache.hadoop.hive.metastore.events.CommitCompactionEvent;
 import org.apache.hadoop.hive.metastore.messaging.EventMessage;
 import org.slf4j.Logger;
@@ -94,7 +95,10 @@ public void setConf(Configuration conf) {
     synchronized (CompactionTxnHandler.class) {
       if (connPoolCompaction == null) {
         int maxPoolSize = MetastoreConf.getIntVar(conf, ConfVars.HIVE_COMPACTOR_CONNECTION_POOLING_MAX_CONNECTIONS);
-        connPoolCompaction = setupJdbcConnectionPool(conf, maxPoolSize);
+        try (DataSourceProvider.DataSourceNameConfigurator configurator =
+                 new DataSourceProvider.DataSourceNameConfigurator(conf, "compactor")) {
+          connPoolCompaction = setupJdbcConnectionPool(conf, maxPoolSize);
+        }
       }
     }
   }
diff --git a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/txn/TxnHandler.java b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/txn/TxnHandler.java
index ca3e79b..1d70f7f 100644
--- a/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/txn/TxnHandler.java
+++ b/standalone-metastore/metastore-server/src/main/java/org/apache/hadoop/hive/metastore/txn/TxnHandler.java
@@ -369,11 +369,15 @@ public void setConf(Configuration conf){
 
     int maxPoolSize = MetastoreConf.getIntVar(conf, ConfVars.CONNECTION_POOLING_MAX_CONNECTIONS);
     synchronized (TxnHandler.class) {
-      if (connPool == null) {
-        connPool = setupJdbcConnectionPool(conf, maxPoolSize);
-      }
-      if (connPoolMutex == null) {
-        connPoolMutex = setupJdbcConnectionPool(conf, maxPoolSize);
+      try (DataSourceProvider.DataSourceNameConfigurator configurator =
+               new DataSourceProvider.DataSourceNameConfigurator(conf, "txnhandler")) {
+        if (connPool == null) {
+          connPool = setupJdbcConnectionPool(conf, maxPoolSize);
+        }
+        if (connPoolMutex == null) {
+          configurator.resetName("mutex");
+          connPoolMutex = setupJdbcConnectionPool(conf, maxPoolSize);
+        }
       }
 
       if (dbProduct == null) {
diff --git a/standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/metastore/datasource/TestDataSourceProviderFactory.java b/standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/metastore/datasource/TestDataSourceProviderFactory.java
index 21f3632..73f8db0 100644
--- a/standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/metastore/datasource/TestDataSourceProviderFactory.java
+++ b/standalone-metastore/metastore-server/src/test/java/org/apache/hadoop/hive/metastore/datasource/TestDataSourceProviderFactory.java
@@ -21,6 +21,7 @@
 
 import org.apache.commons.dbcp2.PoolingDataSource;
 import org.apache.hadoop.conf.Configuration;
+import org.apache.hadoop.hive.metastore.PersistenceManagerProvider;
 import org.apache.hadoop.hive.metastore.annotation.MetastoreUnitTest;
 import org.apache.hadoop.hive.metastore.conf.MetastoreConf;
 import org.apache.hadoop.hive.metastore.conf.MetastoreConf.ConfVars;
@@ -29,7 +30,9 @@
 import org.junit.Test;
 import org.junit.experimental.categories.Category;
 
+import javax.jdo.PersistenceManagerFactory;
 import javax.sql.DataSource;
+import java.sql.Connection;
 import java.sql.SQLException;
 
 @Category(MetastoreUnitTest.class)
@@ -139,4 +142,45 @@ public void testCreateDbCpDataSource() throws SQLException {
     DataSource ds = dsp.create(conf);
     Assert.assertTrue(ds instanceof PoolingDataSource);
   }
+
+  @Test
+  public void testClosePersistenceManagerProvider() throws Exception {
+    String[] dataSourceType = {HikariCPDataSourceProvider.HIKARI, DbCPDataSourceProvider.DBCP};
+    for (String type : dataSourceType) {
+      boolean isHikari = HikariCPDataSourceProvider.HIKARI.equals(type);
+      MetastoreConf.setVar(conf, ConfVars.CONNECTION_POOLING_TYPE, type);
+      PersistenceManagerProvider.updatePmfProperties(conf);
+      PersistenceManagerFactory factory =
+          PersistenceManagerProvider.getPersistenceManager().getPersistenceManagerFactory();
+      DataSource connFactory = (DataSource) factory.getConnectionFactory();
+      DataSource connFactory2 = (DataSource) factory.getConnectionFactory2();
+      factory.close();
+      // Closing PersistenceManagerFactory does not shut down the connection factory
+      // For DBCP, connFactory.getConnection() will return a connection successfully when the pool is not shutdown
+      if (isHikari) {
+        Assert.assertFalse(((HikariDataSource)connFactory).isClosed());
+        Assert.assertFalse(((HikariDataSource)connFactory2).isClosed());
+      }
+      // Underlying connection is still able to run query
+      try (Connection conn = connFactory.getConnection()) {
+        Assert.assertFalse(conn.isClosed());
+      }
+      // Close the underlying connection pools
+      PersistenceManagerProvider.closePmfInternal(factory);
+      if (isHikari) {
+        Assert.assertTrue(((HikariDataSource)connFactory).isClosed());
+        Assert.assertTrue(((HikariDataSource)connFactory2).isClosed());
+      }
+      try {
+        connFactory.getConnection();
+        Assert.fail("Should fail as the DataSource is shutdown");
+      } catch (Exception e) {
+        if (isHikari) {
+          Assert.assertTrue(e instanceof SQLException);
+        } else {
+          Assert.assertTrue(e instanceof IllegalStateException);
+        }
+      }
+    }
+  }
 }
-- 
1.8.3.1

